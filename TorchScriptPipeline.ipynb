{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End TorchScript Pipeline\n",
        "\n",
        "## About\n",
        "\n",
        "In this notebook we will have a hands-on look at the end-to-end TorchScript pipeline where we first refresh some of the idionsyncracies of TorchScript before diving into the customary ResNet-50 example, inspecting how it the pieces connect, and then writing our own model in PyTorch and compiling it with TorchScript."
      ],
      "metadata": {
        "id": "iW9Qo8PcPGxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outline\n",
        "\n",
        "* 1. [Refresher on TorchScript](#torchscript)\n",
        "* 2. [ResNet-50 Example](#resnet-50)\n",
        "* 3. [Writing our own PyTorch Model](#own-model)"
      ],
      "metadata": {
        "id": "CEVg4EEmPGub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get set up we need to install PyTorch and make sure, that we have the right version available to us (1.13.1+cu116)"
      ],
      "metadata": {
        "id": "pYXJj7AiPGfe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C-IZKzQTLU6c"
      },
      "outputs": [],
      "source": [
        "!pip install torch >=1.2.0\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "lFSO7olFLlfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Refresher on TorchScript <a name=\"torchscript\"></a>"
      ],
      "metadata": {
        "id": "PpVyDpEGQjwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin with we first a few simple kernels to inspect the \"rough edges\" of TorchScript which we have to navigate in saving, and exporting our machine learning models."
      ],
      "metadata": {
        "id": "7JH-qlNOQtjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, h = torch.rand(3, 4), torch.rand(3, 4)\n"
      ],
      "metadata": {
        "id": "d256YqioMMrY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecisionGate(torch.nn.Module):\n",
        "  def forward(self, x):\n",
        "    if x.sum() > 0:\n",
        "      return x\n",
        "    else:\n",
        "      return -x\n",
        "\n",
        "class MyCell(torch.nn.Module):\n",
        "    def __init__(self, dg):\n",
        "        super(MyCell, self).__init__()\n",
        "        self.dg = dg\n",
        "        self.linear = torch.nn.Linear(4, 4)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
        "        return new_h, new_h\n",
        "      \n",
        "my_cell = MyCell(MyDecisionGate())\n",
        "traced_cell = torch.jit.trace(my_cell, (x, h))"
      ],
      "metadata": {
        "id": "7VM_QnWXL-MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the model traced, we now have access to two main representations of our model. The graph representation, and the representation in code with which we can inspect whether PyTorch actually traced what we thought it traced."
      ],
      "metadata": {
        "id": "micNqnDLR6gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(traced_cell.graph)"
      ],
      "metadata": {
        "id": "SBq-qDNsMI6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(traced_cell.code)"
      ],
      "metadata": {
        "id": "DT9elLufMRXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No control flow so far. For control flow we need to utilize the **script compiler** to run a direct analysis of the Python source code, and transform it into TorchScript.\n",
        "\n",
        "> If we do not use the script compiler, then TorchScript will only trace the code execution path, but not the entirety of the code with the included control flow."
      ],
      "metadata": {
        "id": "bn24sCVMMZXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_gate = torch.jit.script(MyDecisionGate())\n",
        "\n",
        "my_cell = MyCell(scripted_gate)\n",
        "traced_cell = torch.jit.script(my_cell)\n",
        "print(traced_cell.code)"
      ],
      "metadata": {
        "id": "tkG2G2ctMTp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New inputs\n",
        "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
        "traced_cell(x, h)"
      ],
      "metadata": {
        "id": "TPfAiERXMxof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The traced model can then be saved with the `save` attribute in PyTorch's own traced format `.pt`."
      ],
      "metadata": {
        "id": "VE50flh5M_Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traced_cell.save('Stored_simple_cell.pt')"
      ],
      "metadata": {
        "id": "1JgZLWviM1nN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ResNet-50 Example <a name=\"resnet-50\"></a>"
      ],
      "metadata": {
        "id": "z3SBN_RrStGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To now build up to the ResNet-50 example we seek to utilize the torchvision building blocks."
      ],
      "metadata": {
        "id": "laPThxcDSjr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "ycAKqK4PM8F0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With which we can use the predefined ResNet model, and then trace it through the JIT-compiler."
      ],
      "metadata": {
        "id": "cMsWq5T0S-Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An instance of our model\n",
        "model = torchvision.models.resnet50()\n",
        "\n",
        "# Providing an example input to our model\n",
        "example_input = torch.rand(1, 3, 224, 224)\n",
        "\n",
        "# Tracing the machine learning model\n",
        "traced_script_module = torch.jit.trace(model, example_input)"
      ],
      "metadata": {
        "id": "VOtMm5SiOWX8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traced model can be evaluated just as a regular PyTorch model"
      ],
      "metadata": {
        "id": "tA21ToXJOthZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = traced_script_module(torch.ones(1, 3, 224, 224))\n",
        "output[0, :5]"
      ],
      "metadata": {
        "id": "sAgmjnGgOnLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traced_script_module.save(\"traced_resnet_model.pt\")"
      ],
      "metadata": {
        "id": "v2jUEP5DO4SI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeking to connect this traced model to the C++ layer, we then have to initialize a model loader on the C++ level. For this we define ourselves the following model loader in C++ which includes the libtorch header file\n",
        "\n",
        "```cpp\n",
        "#include <torch/script.h> // One-stop header.\n",
        "\n",
        "#include <iostream>\n",
        "#include <memory>\n",
        "\n",
        "int main(int argc, const char* argv[]) {\n",
        "  if (argc != 2) {\n",
        "    std::cerr << \"usage: example-app <path-to-exported-script-module>\\n\";\n",
        "    return -1;\n",
        "  }\n",
        "\n",
        "\n",
        "  torch::jit::script::Module module;\n",
        "  try {\n",
        "    // Deserialize the ScriptModule from a file using torch::jit::load().\n",
        "    module = torch::jit::load(argv[1]);\n",
        "  }\n",
        "  catch (const c10::Error& e) {\n",
        "    std::cerr << \"error loading the model\\n\";\n",
        "    return -1;\n",
        "  }\n",
        "\n",
        "  std::cout << \"ok\\n\";\n",
        "}\n",
        "```\n",
        "\n",
        "We then use this simple `CMakeLists.txt` file to build our model loader, and connect the individual components\n",
        "\n",
        "```cmake\n",
        "cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\n",
        "project(resnet_test)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "\n",
        "add_executable(model_loader model_loader.cpp)\n",
        "target_link_libraries(model_loader \"${TORCH_LIBRARIES}\")\n",
        "set_property(TARGET model_loader PROPERTY CXX_STANDARD 14)\n",
        "```"
      ],
      "metadata": {
        "id": "4wmeGbk3VtYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The source code for the model loader, as well as the `CMakeLists.txt` are then available from the GitHub repository below"
      ],
      "metadata": {
        "id": "xiJ66vPwTsDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ludgerpaehler/TorchScriptTutorial.git"
      ],
      "metadata": {
        "id": "FjEJVyCuPQLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After which we check the version of the compiler in Google Colab, download the correspondig libtorch, and unzip it"
      ],
      "metadata": {
        "id": "EC-UCwqMXxPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -V"
      ],
      "metadata": {
        "id": "nGeMexCDPbMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/libtorch/nightly/cu118/libtorch-shared-with-deps-latest.zip"
      ],
      "metadata": {
        "id": "hWXBVqJGPsvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip libtorch-shared-with-deps-latest.zip"
      ],
      "metadata": {
        "id": "cXliWpawPwIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following a CMake-typical build workflow, we then navigate to the respective folder, and then set up CMake to build "
      ],
      "metadata": {
        "id": "A_Vz8_0ZT-Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TorchScriptTutorial/"
      ],
      "metadata": {
        "id": "XgxKF7xnS-K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir build"
      ],
      "metadata": {
        "id": "WSPYVoRxTbpk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd build"
      ],
      "metadata": {
        "id": "__1wpaWtTeH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake -DCMAKE_PREFIX_PATH=/content/libtorch .."
      ],
      "metadata": {
        "id": "AGvjCZsNTEuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake --build . --config Release"
      ],
      "metadata": {
        "id": "oquMgX2WTKl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Going back to the root folder, where we previously stored the traced model"
      ],
      "metadata": {
        "id": "6Rx9ZKxqUm7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../.."
      ],
      "metadata": {
        "id": "g6bxXiYXTR8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting that we are in the right directory, and the model have been saved correctly"
      ],
      "metadata": {
        "id": "xdu8BniKZHjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq14WhQBUIMJ",
        "outputId": "c647414a-7948-442f-9ecc-a9ffd225e9b0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4548536\n",
            "-rw-r--r-- 1 root root        305 Mar  2 16:36 '=1.2.0'\n",
            "drwxr-xr-x 2 root root       4096 Mar  2 17:08  build\n",
            "drwxr-xr-x 6 root root       4096 Mar  2 09:20  libtorch\n",
            "-rw-r--r-- 1 root root 2305344701 Mar  2 10:29  libtorch-shared-with-deps-latest.zip\n",
            "-rw-r--r-- 1 root root 2305344701 Mar  2 10:29  libtorch-shared-with-deps-latest.zip.1\n",
            "drwxr-xr-x 1 root root       4096 Feb 28 14:45  sample_data\n",
            "-rw-r--r-- 1 root root       4679 Mar  2 17:20  Stored_simple_cell.pt\n",
            "-rw-r--r-- 1 root root       4679 Mar  2 16:44  Stored_simple_cell.zip\n",
            "drwxr-xr-x 4 root root       4096 Mar  2 17:32  TorchScriptTutorial\n",
            "-rw-r--r-- 1 root root   46959061 Mar  2 16:52  traced_resnet_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now execute the model loader to make sure that our model has been traced correctly, and can be loaded."
      ],
      "metadata": {
        "id": "qDrv4i75U0nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./TorchScriptTutorial/build/model_loader traced_resnet_model.pt"
      ],
      "metadata": {
        "id": "Dd5cRaDUUJIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With which we can conclude that we have traced our PyTorch model correctly, and can now use the traced model in any number of further backends such as [TVM](https://tvm.apache.org), and [ONNX](https://onnx.ai). [IREE](https://openxla.github.io/iree/#importing-models-from-ml-frameworks) requires our model to be legalized to MLIR's `linalg` dialect which we are unable to test in the same notebook."
      ],
      "metadata": {
        "id": "zR8leF4MZUXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Writing our own PyTorch Model <a name=\"own-model\"></a>"
      ],
      "metadata": {
        "id": "Eh-n7-P9VGDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To now define our own PyTorch model we only have to write down the model, save it, and test its correctness with the compiled model loader"
      ],
      "metadata": {
        "id": "6kk9UlIHVOev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OurMLModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(OurMLModel, self).__init__()\n",
        "    ...\n",
        "\n",
        "  def forward(self):\n",
        "    ..."
      ],
      "metadata": {
        "id": "wSTVfhRKVN4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then have to trace the model through the JIT"
      ],
      "metadata": {
        "id": "bweY4sU7WQIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "own_ml_model = OurMLModel()\n",
        "traced_own_model = torch.jit.trace(own_ml_model, example_input)"
      ],
      "metadata": {
        "id": "MmDLWb4aWOn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then save the model"
      ],
      "metadata": {
        "id": "KxqdaZaiWW_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traced_own_model.save('traced_own_model.pt')"
      ],
      "metadata": {
        "id": "LAoOMHizWZc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After which we can test it with the model loader"
      ],
      "metadata": {
        "id": "a4BaJyzqWZ8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./TorchScriptTutorial/build/model_loader traced_own_model.pt"
      ],
      "metadata": {
        "id": "pL_TNt4FWcDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}